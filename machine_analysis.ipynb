{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzAx1rmqYIzdGZyPqvLZ8k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ambrose70/Applied-Data-science/blob/main/machine_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries and Define Auxiliary Functions**"
      ],
      "metadata": {
        "id": "cOATrJMkZJE_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ebtkx2NHZFlw"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
        "import pandas as pd\n",
        "# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
        "import numpy as np\n",
        "# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.\n",
        "import matplotlib.pyplot as plt\n",
        "#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\n",
        "import seaborn as sns\n",
        "# Preprocessing allows us to standarsize our data\n",
        "from sklearn import preprocessing\n",
        "# Allows us to split our data into training and testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Allows us to test parameters of classification algorithms and find the best one\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Logistic Regression classification algorithm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Support Vector Machine classification algorithm\n",
        "from sklearn.svm import SVC\n",
        "# Decision Tree classification algorithm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# K Nearest Neighbors classification algorithm\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "YZ2O0OjQZf7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This function is to plot the confusion matrix.**"
      ],
      "metadata": {
        "id": "VVw2Gt1maBc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y,y_predict):\n",
        "    \"this function plots the confusion matrix\"\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    cm = confusion_matrix(y, y_predict)\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')\n",
        "    ax.set_title('Confusion Matrix');\n",
        "    ax.xaxis.set_ticklabels(['did not land', 'land']); ax.yaxis.set_ticklabels(['did not land', 'landed'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bJGktpq-aFen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the dataframe**"
      ],
      "metadata": {
        "id": "vbH-efHiaLa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "URL1 = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv\"\n",
        "resp1 = requests.get(URL1)\n",
        "text1 = io.BytesIO(resp1.content)\n",
        "data = pd.read_csv(text1)\n",
        "\n",
        "display(data.head())"
      ],
      "metadata": {
        "id": "UZ3LhYr7aNAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "URL2 = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_3.csv'\n",
        "resp2 = requests.get(URL2)\n",
        "text2 = io.BytesIO(resp2.content)\n",
        "X = pd.read_csv(text2)\n",
        "\n",
        "display(X.head())"
      ],
      "metadata": {
        "id": "kVqUIxF8aTt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 1**"
      ],
      "metadata": {
        "id": "J7v3mkEcadZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = data['Class'].to_numpy()\n",
        "display(Y)"
      ],
      "metadata": {
        "id": "5n8PNDqrafPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 2**"
      ],
      "metadata": {
        "id": "zIeoGprtam8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# students get this\n",
        "transform = preprocessing.StandardScaler()"
      ],
      "metadata": {
        "id": "BQOn4ddzapIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 3**"
      ],
      "metadata": {
        "id": "V7QLp6n1avrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "print ('Train set:', X_train.shape,  Y_train.shape)\n",
        "print ('Test set:', X_test.shape,  Y_test.shape)"
      ],
      "metadata": {
        "id": "SdxB9BF4ax21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 4**"
      ],
      "metadata": {
        "id": "5EQgodYpa-TY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters ={'C':[0.01,0.1,1],\n",
        "             'penalty':['l2'],\n",
        "             'solver':['lbfgs']}"
      ],
      "metadata": {
        "id": "saCcCjOQbACE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters ={\"C\":[0.01,0.1,1],'penalty':['l2'], 'solver':['lbfgs']}# l1 lasso l2 ridge\n",
        "lr=LogisticRegression()"
      ],
      "metadata": {
        "id": "IF434GnnbENp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_cv = GridSearchCV(lr, parameters, cv=10)\n",
        "logreg_cv.fit(X_train, Y_train)\n",
        "\n",
        "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
        "print(\"accuracy :\",logreg_cv.best_score_)"
      ],
      "metadata": {
        "id": "WJ9Mq9S_bHy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 5**"
      ],
      "metadata": {
        "id": "8IDqScpJbtoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy of the Logistic Regression model on the test data\n",
        "logreg_accuracy = logreg_cv.score(X_test, Y_test)\n",
        "print(\"Accuracy of Logistic Regression model on test data: \", logreg_accuracy)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "yhat_logreg = logreg_cv.predict(X_test)\n",
        "\n",
        "# Plot the confusion matrix for the Logistic Regression model\n",
        "plot_confusion_matrix(Y_test, yhat_logreg)"
      ],
      "metadata": {
        "id": "622Wny70bX4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK  6**"
      ],
      "metadata": {
        "id": "LsunSmLwb0mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'),\n",
        "              'C': np.logspace(-3, 3, 5),\n",
        "              'gamma':np.logspace(-3, 3, 5)}\n",
        "svm = SVC()"
      ],
      "metadata": {
        "id": "ov04gJ_gb5a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_cv = GridSearchCV(svm, parameters, cv=10)\n",
        "svm_cv.fit(X_train, Y_train)\n",
        "\n",
        "print(\"tuned hpyerparameters :(best parameters) \",svm_cv.best_params_)\n",
        "print(\"accuracy :\",svm_cv.best_score_)"
      ],
      "metadata": {
        "id": "rxWMoowwb-IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 7**"
      ],
      "metadata": {
        "id": "_ho87e9zcFDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy of the SVM model on the test data\n",
        "svm_accuracy = svm_cv.score(X_test, Y_test)\n",
        "print(\"Accuracy of SVM model on test data: \", svm_accuracy)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "yhat_svm = svm_cv.predict(X_test)\n",
        "\n",
        "# Plot the confusion matrix for the SVM model\n",
        "plot_confusion_matrix(Y_test, yhat_svm)"
      ],
      "metadata": {
        "id": "2fkKKzVGcHBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat=svm_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "ZeaPKafgd5qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 8**"
      ],
      "metadata": {
        "id": "bjLvC9eId9W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'criterion': ['gini', 'entropy'],\n",
        "     'splitter': ['best', 'random'],\n",
        "     'max_depth': [2*n for n in range(1,10)],\n",
        "     'max_features': ['auto', 'sqrt'],\n",
        "     'min_samples_leaf': [1, 2, 4],\n",
        "     'min_samples_split': [2, 5, 10]}\n",
        "\n",
        "tree = DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "sCcqXX95eBVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tuned hpyerparameters :(best parameters) \",tree_cv.best_params_)\n",
        "print(\"accuracy :\",tree_cv.best_score_)"
      ],
      "metadata": {
        "id": "XG2lKY4beF10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 9**"
      ],
      "metadata": {
        "id": "fxULz5A9eLQb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YzA3KF3WeMxk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}